---
title: "Classification Approaches"
author: "Dima"
date: "September 14, 2015"
output: html_document
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(njtPredict)
library(lubridate)
library(ggplot2)
library(tidyr)
library(knitr)
library(caret)
# devtools::load_all() #Toggle if not in the mood to rebuild after change
data("njt_features")

opts_chunk$set(echo = TRUE,
               message = FALSE,
               prompt = FALSE,
               warning = FALSE,
               cache = TRUE)
```

```{r feature_cleanup}
tr_ctrl <- trainControl(method="cv", number=5, savePred = TRUE, classProb = TRUE)

tr_data <- njt_features %>% 
  # select(is_delayed, Line, dep_hour, dep_mon, dep_wday, prdelay, Temp_F, Visibility, WindSpeed, HourlyPrecip) %>%
  ungroup %>% 
  mutate(Line = gsub(" " , "_", Line),
         is_delayed = factor(is_delayed, levels = c(TRUE,FALSE), labels = c("Yes","No")),
         ttl_90 = ttl_line <= 90) %>% 
  select(-Actual_End_Time, -delay_length, -ttl_dep_arv_line) # Need to remove this field for the complete.cases function (not a feature I'll use anyway)
tr_data <- tr_data[complete.cases(tr_data), ] #Removes only about 8K entries

#Using downsampling per "Line" to account for the Unbalanced training data
tr_ds <- tr_data %>% group_by(Line) %>% do(downSample(., .$is_delayed))

#Alternative is to downsample the whole dataset, but this would result in negatives mostly coming from lines with MANY entries
# tr_data <- downSample(tr_data, tr_data$is_delayed)
```

```{r}
formula = Class ~ 
  as.factor(dep_hour) + 
  as.character(dep_wday) + 
  ttl_line +
  Temp_F + 
  Visibility + 
  WindSpeed + 
  HourlyPrecip
testModel <- function(df, tr_ctrl, method = "glm", formula, ...){
  ds_df <- df %>% droplevels()
  fit <- train(formula, data = ds_df, method = method, trControl = tr_ctrl, ...)
  pred <-  predict(fit, ds_df)
  cm <- confusionMatrix(pred, ds_df$Class)
  
  # Get AUC per Fold
  roc_eval <- fit$pred %>% 
    group_by(Resample) %>% 
    arrange(desc(Yes)) %>% 
    mutate(obs = ifelse(obs == "Yes",1,0)) %>%
    summarise(auc = auc(roc(obs,Yes)))
  roc_vec <- as.vector(roc_eval$auc)
  names(roc_vec) <- roc_eval$Resample
  data.frame(t(c(cm$overall, cm$byClass, roc_vec)))
}

#Using all data
results_dslogit_all <- testModel(tr_ds, tr_ctrl, method = "glm", family = "binomial", formula)

results_dslogit_byline <- tr_ds %>% group_by(Line) %>% do(testModel(.,tr_ctrl, method = "glm", family = "binomial", formula))

```

# Random Forest

```{r}
rf_fit <- train(formula, data = tr_ds, method = "rf", trControl = tr_ctrl, ntree = 80)
rf_pred <-  predict(rf_fit, tr_ds)
cm <- confusionMatrix(rf_pred, tr_ds$Class)
plot(varImp(rf_fit))
```

```{r}
roc_eval <- rf_fit$pred %>% 
  group_by(Resample) %>% 
  arrange(desc(Yes)) %>% 
  mutate(obs = ifelse(obs == "Yes",1,0))
roc_eval %>% summarise(auc = auc(roc(obs,Yes)))
```

```{r}
results_dsrf_all <- testModel(tr_ds, tr_ctrl, method = "rf", formula, ntree=80)
results_dslrf_byline <- tr_ds %>% group_by(Line) %>% do(testModel(.,tr_ctrl, method = "rf", formula, ntree = 80))
```



```{r}
cmp_summ <- rbind(results_dslogit_all %>% mutate(Line="ALL", method = "Logistic Regression"),
results_dsrf_all %>% mutate(Line = "ALL", method = "Random Forrest"),
results_dslogit_byline %>% mutate(method = "Logistic Regression"),
results_dslrf_byline %>% mutate(method = "Random Forrest"))

cmp_summ <- cmp_summ %>% gather("Fold","auc",Fold1:Fold5)

```

```{r}
cmp_summ <- cmp_summ %>% 
  mutate(breakdown = ifelse(Line == "ALL","All_Line","By_Line")) %>% 
  mutate(Line = relevel(factor(Line), ref = "ALL")) %>% 
  filter(Line == "ALL")
ggplot(cmp_summ, aes(breakdown, auc, fill = method)) + geom_boxplot() + theme_bw()

library(gridExtra)

p1 <- ggplot(cmp_summ, aes(method, Accuracy, fill = method)) + geom_bar(stat="identity", position = 'dodge') + theme_bw() + ggtitle("Accuracy")+ guides(fill=FALSE) + xlab("") + scale_fill_hue(l=40)

p2 <- ggplot(cmp_summ, aes(method, Sensitivity, fill = method)) + geom_bar(stat="identity", position = 'dodge') + theme_bw() + ggtitle("Sensitivity")+ guides(fill=FALSE)+ xlab("")+ scale_fill_hue(l=40)

# ggplot(cmp_summ, aes(Line, Specificity, fill = method)) + geom_bar(stat="identity", position = 'dodge') + theme_bw() + ggtitle("Specificity")
p3 <- cmp_summ %>% group_by(Line, method) %>% summarise(meanauc = mean(auc)) %>% ggplot(aes(method,meanauc, fill = method)) + geom_bar(stat = 'identity', position = 'dodge') + theme_bw() +ggtitle("meanAUC")+ guides(fill=FALSE)+ xlab("")+ scale_fill_hue(l=40)

grid.arrange(p1,p2,p3, ncol=3)


```

#Downsamples  /Reweighting

```{r}
njt_featdaily <- njt_featdaily  %>% mutate(is_delayed = as.factor(number_delays>0))
daily_formula <- is_delayed ~ Line + as.character(dep_mon) + as.character(dep_wday) + Tmin + Tavg + PrecipTotal + SnowFall + WindSpeed
fit <- train(daily_formula, data = njt_featdaily, method = "glm", family = "binomial", tr_ctrl = trainControl(method="cv", number=2, savePred = TRUE, classProb = TRUE))
pred <-  predict(fit, njt_featdaily)
cm <- confusionMatrix(pred, njt_featdaily$number_delays)
```

