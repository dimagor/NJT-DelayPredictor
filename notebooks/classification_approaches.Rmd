---
title: "Classification Approaches Comparison"
author: "Dima"
date: "September 14, 2015"
output: html_document
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
# library(njtPredict)
library(lubridate)
library(ggplot2)
library(tidyr)
library(knitr)
library(caret)
# devtools::load_all() #Toggle if not in the mood to rebuild after change
data("njt_features")

opts_chunk$set(echo = TRUE,
               message = FALSE,
               prompt = FALSE,
               warning = FALSE,
               cache = TRUE)
```

```{r feature_cleanup}
tr_data <- njt_features %>% 
  # select(is_delayed, Line, dep_hour, dep_mon, dep_wday, prdelay, Temp_F, Visibility, WindSpeed, HourlyPrecip) %>%
  ungroup %>% 
  mutate(Line = gsub(" " , "_", Line),
         is_delayed = factor(is_delayed, levels = c(TRUE,FALSE), labels = c("Yes","No"))) %>% 
  # Need to remove these fields for the complete.cases function (not a feature I'll use anyway) 
  select(-Actual_End_Time, -delay_length, -ttl_dep_arv_line)
tr_data <- tr_data[complete.cases(tr_data), ] #Removes only about 8K entries

#Using downsampling per "Line" to account for the Unbalanced training data
data_downsampled <- tr_data %>% group_by(Line) %>% do(downSample(., .$is_delayed))
```

# Model Selection
```{r}
library(doMC)
registerDoMC(cores = 7)
train_control <- trainControl(method = "repeatedcv",
                              number = 5,
                              repeats = 10,
                              ## Estimate class probabilities
                              classProbs = TRUE,
                              ## Evaluate performance using 
                              ## the following function
                              summaryFunction = twoClassSummary)
line_formula <- Class ~ Line +
  as.factor(dep_hour) + 
  as.character(dep_wday) +
  as.character(dep_mon) + 
  ttl_line +
  Temp_F + 
  Visibility + 
  WindSpeed

# Withold 20% of the data for an independent evaluation
in_train <- createDataPartition(data_downsampled$Class, p=.80, list=FALSE)
training <- data_downsampled[in_train, ]
testing <- data_downsampled[-in_train, ]
save(in_train, training, testing, train_control, file = "data/training_data.rda")
```

```{r model_train, eval = FALSE}
logit_fit <- train(line_formula,
                   data = training,
                   tuneLength = 10,
                   trControl = train_control,
                   method = "glm",
                   family = "binomial",
                   metric = "ROC")
save(logit_fit, "data/logit_fit.rda")

glmnet_fit <- train(line_formula,
                   data = training,
                   tuneLength = 10,
                   trControl = train_control,
                   method = "glmnet",
                   family = "binomial",
                   metric = "ROC")
save(glmnet_fit, file = "data/glmnet_fit.rda")

rf_fit <- train(line_formula,
                data = training,
                tuneLength = 10,
                trControl = train_control,
                metric = "ROC", 
                method = "rf",
                ntree = 80)
save(rf_fit, file = "data/rf_fit.rda")

gbm_fit <- train(line_formula,
                data = training,
                tuneLength = 10,
                trControl = train_control,
                metric = "ROC", 
                method = "gbm")
save(gbm_fit, file = "data/gbm_fit.rda")

knn_fit <- train(line_formula,
                data = training,
                tuneLength = 10,
                trControl = train_control,
                metric = "ROC", 
                method = "knn",
                preProc = c("center", "scale"))
save(knn_fit, file =  "data/knn_fit.rda")

# 
# smvlin_fit <- train(line_formula,
#                 data = training,
#                 tuneLength = 5,
#                 trControl = train_control,
#                 metric = "ROC", 
#                 method = "svmLinear",
#                 preProc = c("center", "scale"))
# save(svmlin_fit, file = "data/svmlin_fit.rda")


```

```{r}
resamps <- resamples(list("Loistic Regression" = logit_fit, "GLMNet" = glmnet_fit, "Random Forest" = rf_fit, "KNN" = knn_fit))
diff(resamps)  %>% summary
<<<<<<< HEAD
bwplot(resamp, layout = c(3, 1))
=======
>>>>>>> 8938e8e1af6a20d8975bf8196581701653f8fe21
```

# Testing the Model
```{r}
model_predictions <- predict(rf_fit, testing)
confusionMatrix(model_predictions, testing$Class)
```

# Needs Updating
## Random Forest

```{r}
rf_fit <- train(formula, data = tr_ds, method = "rf", trControl = tr_ctrl, ntree = 80)
rf_pred <-  predict(rf_fit, tr_ds)
cm <- confusionMatrix(rf_pred, tr_ds$Class)
plot(varImp(rf_fit))
rf_fit -> modelfit
save(modelfit, file = "../../DelayPredictor/modelfit.rda")
```


```{r}
modelfit_byline <- tr_ds %>% group_by(Line) %>% do(fit = train(Class ~ 
                                                                 as.factor(dep_hour) + 
                                                                 as.character(dep_wday) +
                                                                 dep_mon + 
                                                                 ttl_line +
                                                                 Temp_F + 
                                                                 Visibility + 
                                                                 WindSpeed,
                                                               data = ., method = "rf", trControl = tr_ctrl, ntree = 80))
save(modelfit_byline, file = "../../DelayPredictor/modelfit_byline.rda")
```




## Separate Holdout
```{r}
library(pROC)
tr_ctrl = trainControl(method = "cv",
                              number = 5,
                       savePredictions = TRUE,
                       classProb = TRUE)

testModelHoldout <- function(df, tr_ctrl, method = "glm", formula, ...){
  ds_df <- df %>% droplevels()
  in_partition <- createDataPartition(ds_df$Class, p=.75, list=FALSE)
  fit <- train(formula, data = ds_df, method = method, trControl = tr_ctrl, subset = in_partition, ...)
  
  test_set <- ds_df[-in_partition,]
  test_set$pred <-  predict(fit, ds_df[-in_partition,])
  test_set$pred_prob <-  predict(fit, ds_df[-in_partition,], type = "prob")$Yes
  cm <- confusionMatrix(test_set$pred, test_set$Class)
  
  # Get AUC per Fold
  roc_eval <- test_set %>% 
    arrange(desc(pred_prob)) %>% 
    mutate(Class = ifelse(Class == "Yes",1,0)) %>%
    summarise(auc = auc(roc(Class,pred_prob)))
  data.frame(t(c(cm$overall, cm$byClass)),"AUC" = roc_eval$auc)
}
formula_byline <- Class ~ 
  as.factor(dep_hour) + 
  as.character(dep_wday) + 
  ttl_line +
  Temp_F + 
  Visibility + 
  WindSpeed
results_ho_byline <- data_downsampled %>% group_by(Line) %>% do(testModelHoldout(.,tr_ctrl, method = "rf", formula_byline, ntree = 80))
```
